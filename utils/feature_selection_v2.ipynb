{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/jogi/git/repository/smart_play_set')\n",
    "from itertools import compress\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import fft, arange, fftpack\n",
    "\n",
    "from utils.smart_utils import get_dir_path, tensor_to_pandas, load_hdf5_file\n",
    "from utils.smart_utils import get_array_filenames, split_on_classes, create_row_mask\n",
    "from preprocessing.process_data import get_data\n",
    "\n",
    "from utils.plot_utils import plot_spectra_1axis, plot_spectra_3axis\n",
    "from utils.plot_utils import plot_3axis_raw_signal_1, plot_3axis_raw_signal_compare\n",
    "from utils.plot_utils import single_file_plots, load_file_to_pandas\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from ReliefF import ReliefF\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Used data label 20160921_futurocube_roadrunner_20hz_1axis_f2.01.5_12f_207_12_1\n",
      "INFO Loading matrices from h5 file /home/jogi/git/repository/smart_play_set/data/futurocube/roadrunner/20160921_futurocube_roadrunner_20hz_1axis_f2.01.5_12f_207_12_1.h5\n",
      "('INFO - List of arrays in this file: \\n', [u'feature_data', u'label_data'])\n",
      "INFO - Loading data description from json.\n",
      "(207, 12)\n",
      "(207,)\n",
      "[u'minf', u'maxf', u'mean', u'std', u'median', u'range', u'rms', u'int_squared_jerk', u'dc', u'energy', u'power_spec_entropy', u'dxdy_error']\n",
      "lowhigh\n",
      "[2, 0.1, 5]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_data_1, train_labels_1, dta_dict_1 = get_data('20160921', force=False, apply_window_func=True, calc_mag=True,\n",
    "                                              extra_label=\"20hz_1axis_f2.01.5_12f_207_12_1\", optimal_w_size=False,\n",
    "                                                   f_type='lowhigh', lowcut=2, highcut=0.1, b_order=5)\n",
    "                                     \n",
    "                # calc_mag=True, f_type=\"lowhigh\", lowcut=2, highcut=0.1, b_order=5)\n",
    "        \n",
    "# for cross validation train data has to have 2 dim tensor\n",
    "train_data_1_r = np.reshape(train_data_1, (train_data_1.shape[0], train_data_1.shape[1] * train_data_1.shape[2]))\n",
    "# for cross validation train labels has to have 1 dim tensor\n",
    "train_labels_1_r = np.reshape(train_labels_1, (train_labels_1.shape[0]))\n",
    "print(train_data_1_r.shape)\n",
    "print(train_labels_1_r.shape)\n",
    "print(dta_dict_1[\"features\"])\n",
    "print(dta_dict_1[\"filter\"])\n",
    "print(dta_dict_1[\"filter_specs\"])\n",
    "print(dta_dict_1[\"window_func\"])\n",
    "num_of_features_1 = len(dta_dict_1[\"features\"])\n",
    "features1 = dta_dict_1[\"features\"]\n",
    "num_of_windows1 = dta_dict_1[\"num_of_windows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Used data label 20160921_futurocube_roadrunner_20hz_1axis_f2.01.5_10f_45_10_1\n",
      "INFO Loading matrices from h5 file /home/jogi/git/repository/smart_play_set/data/futurocube/roadrunner/20160921_futurocube_roadrunner_20hz_1axis_f2.01.5_10f_45_10_1.h5\n",
      "('INFO - List of arrays in this file: \\n', [u'feature_data', u'label_data'])\n",
      "INFO - Loading data description from json.\n",
      "(45, 10)\n",
      "(45,)\n",
      "[u'min', u'max', u'mean', u'std', u'median', u'rms', u'range', u'dc', u'energy', u'power_spec_entropy']\n",
      "lowhigh\n",
      "[2, 0.1, 5]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_data_2, train_labels_2, dta_dict_2 = get_data('20160921', force=False, apply_window_func=True, calc_mag=True,\n",
    "                                              extra_label=\"20hz_1axis_f2.01.5_10f_45_10_1\", optimal_w_size=False,\n",
    "                                                   f_type='lowhigh', lowcut=2, highcut=0.1, b_order=5)\n",
    "\n",
    "# for cross validation train data has to have 2 dim tensor\n",
    "train_data_2_r = np.reshape(train_data_2, (train_data_2.shape[0], train_data_2.shape[1] * train_data_2.shape[2]))\n",
    "# for cross validation train labels has to have 1 dim tensor\n",
    "train_labels_2_r = np.reshape(train_labels_2, (train_labels_2.shape[0]))\n",
    "print(train_data_2_r.shape)\n",
    "print(train_labels_2_r.shape)\n",
    "\n",
    "print(dta_dict_2[\"features\"])\n",
    "print(dta_dict_2[\"filter\"])\n",
    "print(dta_dict_2[\"filter_specs\"])\n",
    "print(dta_dict_2[\"window_func\"])\n",
    "num_of_features_2 = len(dta_dict_2[\"features\"])\n",
    "features2 = dta_dict_2[\"features\"]\n",
    "num_of_windows2 = dta_dict_2[\"num_of_windows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use set train_data_1 !\n",
      "--------------------------------------------------------------\n",
      "Keep 1, top feature list: minf\n",
      "SVM - Accuracy: 0.58 (+/- 0.29)\n",
      "rfc - Accuracy: 0.58 (+/- 0.29)\n",
      "xgb - Accuracy: 0.58 (+/- 0.29)\n",
      "gnb - Accuracy: 0.59 (+/- 0.22)\n",
      "--------------------------------------------------------------\n",
      "Keep 2, top feature list: minf, maxf\n",
      "SVM - Accuracy: 0.60 (+/- 0.32)\n",
      "rfc - Accuracy: 0.60 (+/- 0.32)\n",
      "xgb - Accuracy: 0.60 (+/- 0.32)\n",
      "gnb - Accuracy: 0.55 (+/- 0.26)\n",
      "--------------------------------------------------------------\n",
      "Keep 3, top feature list: minf, maxf, range\n",
      "SVM - Accuracy: 0.61 (+/- 0.32)\n",
      "rfc - Accuracy: 0.61 (+/- 0.32)\n",
      "xgb - Accuracy: 0.61 (+/- 0.32)\n",
      "gnb - Accuracy: 0.56 (+/- 0.23)\n",
      "--------------------------------------------------------------\n",
      "Keep 4, top feature list: minf, maxf, range, dxdy_error\n",
      "SVM - Accuracy: 0.56 (+/- 0.34)\n",
      "rfc - Accuracy: 0.56 (+/- 0.34)\n",
      "xgb - Accuracy: 0.56 (+/- 0.34)\n",
      "gnb - Accuracy: 0.60 (+/- 0.20)\n",
      "--------------------------------------------------------------\n",
      "Keep 5, top feature list: minf, maxf, range, dxdy_error, median\n",
      "SVM - Accuracy: 0.57 (+/- 0.25)\n",
      "rfc - Accuracy: 0.57 (+/- 0.25)\n",
      "xgb - Accuracy: 0.57 (+/- 0.25)\n",
      "gnb - Accuracy: 0.58 (+/- 0.21)\n",
      "--------------------------------------------------------------\n",
      "Keep 6, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy\n",
      "SVM - Accuracy: 0.57 (+/- 0.22)\n",
      "rfc - Accuracy: 0.57 (+/- 0.22)\n",
      "xgb - Accuracy: 0.57 (+/- 0.22)\n",
      "gnb - Accuracy: 0.57 (+/- 0.23)\n",
      "--------------------------------------------------------------\n",
      "Keep 7, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy, energy\n",
      "SVM - Accuracy: 0.58 (+/- 0.26)\n",
      "rfc - Accuracy: 0.58 (+/- 0.26)\n",
      "xgb - Accuracy: 0.58 (+/- 0.26)\n",
      "gnb - Accuracy: 0.60 (+/- 0.23)\n",
      "--------------------------------------------------------------\n",
      "Keep 8, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy, energy, dc\n",
      "SVM - Accuracy: 0.58 (+/- 0.27)\n",
      "rfc - Accuracy: 0.58 (+/- 0.27)\n",
      "xgb - Accuracy: 0.58 (+/- 0.27)\n",
      "gnb - Accuracy: 0.59 (+/- 0.24)\n",
      "--------------------------------------------------------------\n",
      "Keep 9, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy, energy, dc, int_squared_jerk\n",
      "SVM - Accuracy: 0.61 (+/- 0.29)\n",
      "rfc - Accuracy: 0.61 (+/- 0.29)\n",
      "xgb - Accuracy: 0.61 (+/- 0.29)\n",
      "gnb - Accuracy: 0.59 (+/- 0.28)\n",
      "--------------------------------------------------------------\n",
      "Keep 10, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy, energy, dc, int_squared_jerk, rms\n",
      "SVM - Accuracy: 0.58 (+/- 0.31)\n",
      "rfc - Accuracy: 0.58 (+/- 0.31)\n",
      "xgb - Accuracy: 0.58 (+/- 0.31)\n",
      "gnb - Accuracy: 0.58 (+/- 0.31)\n",
      "--------------------------------------------------------------\n",
      "Keep 11, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy, energy, dc, int_squared_jerk, rms, std\n",
      "SVM - Accuracy: 0.66 (+/- 0.24)\n",
      "rfc - Accuracy: 0.66 (+/- 0.24)\n",
      "xgb - Accuracy: 0.66 (+/- 0.24)\n",
      "gnb - Accuracy: 0.58 (+/- 0.32)\n",
      "--------------------------------------------------------------\n",
      "Keep 12, top feature list: minf, maxf, range, dxdy_error, median, power_spec_entropy, energy, dc, int_squared_jerk, rms, std, mean\n",
      "SVM - Accuracy: 0.65 (+/- 0.23)\n",
      "rfc - Accuracy: 0.65 (+/- 0.23)\n",
      "xgb - Accuracy: 0.65 (+/- 0.23)\n",
      "gnb - Accuracy: 0.58 (+/- 0.31)\n"
     ]
    }
   ],
   "source": [
    "use_1 = True\n",
    "apply_mask = False\n",
    "\n",
    "if use_1:\n",
    "    print(\"Use set train_data_1 !\")\n",
    "    dta_train = train_data_1_r\n",
    "    lbl_train = train_labels_1_r\n",
    "    num_of_features = num_of_features_1\n",
    "    features = features1\n",
    "    num_of_windows = num_of_windows1\n",
    "else:\n",
    "    print(\"Use set train_data_2 !\")\n",
    "    dta_train = train_data_2_r\n",
    "    lbl_train = train_labels_2_r\n",
    "    num_of_features = num_of_features_2\n",
    "    features = features2\n",
    "    num_of_windows = num_of_windows2\n",
    "\n",
    "for d in np.arange(num_of_features):\n",
    "    idx = d+1\n",
    "    fs = ReliefF(n_neighbors=10, n_features_to_keep=idx)\n",
    "    X_train_2 = fs.fit_transform(dta_train, lbl_train)\n",
    "    X_train_2 = fs.transform(dta_train)\n",
    "    f_list = [features[i] for i in fs.top_features]\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"Keep %d, top feature list: %s\" % (idx, ', '.join(f_list[:idx])))\n",
    "\n",
    "    if apply_mask:\n",
    "        multiplier = int(X_train_2.shape[0]/num_of_windows)\n",
    "        b_mask = create_row_mask([False, False, True, False, True], multiplier)\n",
    "        X_train_2 = X_train_2[b_mask, :]\n",
    "        lbl_train_subset = lbl_train[b_mask]\n",
    "    else:\n",
    "        lbl_train_subset = lbl_train\n",
    "    \n",
    "    clf = svm.SVC(kernel='rbf', C=1)\n",
    "    scores_svm = cross_validation.cross_val_score(clf, X_train_2, lbl_train_subset, cv=12)\n",
    "    # predicted = cross_val_predict(clf, X_train_f, train_labels_f_r, cv=8)\n",
    "    # print(predicted)\n",
    "    # scores = accuracy_score(train_labels_r, predicted) \n",
    "    print(\"SVM - Accuracy: %0.2f (+/- %0.2f)\" % (scores_svm.mean(), scores_svm.std() * 2))\n",
    "    \n",
    "    rfc = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "    scores_rfc = cross_validation.cross_val_score(clf, X_train_2, lbl_train_subset, cv=12)\n",
    "    print(\"rfc - Accuracy: %0.2f (+/- %0.2f)\" % (scores_rfc.mean(), scores_rfc.std() * 2))\n",
    "    \n",
    "    xgb = XGBClassifier(learning_rate=0.1, n_estimators=300, max_depth=5, min_child_weight=2, gamma=0.1,\n",
    "                         subsample=0.8, colsample_bytree=0.8, objective= 'binary:logistic', nthread=4,\n",
    "                         scale_pos_weight=1, seed=27)\n",
    "    scores_xgb = cross_validation.cross_val_score(clf, X_train_2, lbl_train_subset, cv=12)\n",
    "    print(\"xgb - Accuracy: %0.2f (+/- %0.2f)\" % (scores_xgb.mean(), scores_xgb.std() * 2))\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    scores_gnb = cross_validation.cross_val_score(gnb, X_train_2, lbl_train_subset, cv=12)\n",
    "    print(\"gnb - Accuracy: %0.2f (+/- %0.2f)\" % (scores_gnb.mean(), scores_gnb.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use set train_data_1 !\n",
      "Keep feature(s) std\n",
      "[False False False  True False False False False False]\n",
      "[3 2 6 1 9 8 4 7 5]\n",
      "(27, 1)\n",
      "SVM - Accuracy: 0.54 (+/- 0.43)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) maxf, std\n",
      "[False  True False  True False False False False False]\n",
      "[2 1 5 1 8 7 3 6 4]\n",
      "(27, 2)\n",
      "SVM - Accuracy: 0.61 (+/- 0.55)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) minf, maxf, std\n",
      "[ True  True False  True False False False False False]\n",
      "[1 1 4 1 7 6 2 5 3]\n",
      "(27, 3)\n",
      "SVM - Accuracy: 0.60 (+/- 0.40)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) minf, maxf, std, dc\n",
      "[ True  True False  True False False  True False False]\n",
      "[1 1 3 1 6 5 1 4 2]\n",
      "(27, 4)\n",
      "SVM - Accuracy: 0.82 (+/- 0.44)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) minf, maxf, std, dc, power_spec_entropy\n",
      "[ True  True False  True False False  True False  True]\n",
      "[1 1 2 1 5 4 1 3 1]\n",
      "(27, 5)\n",
      "SVM - Accuracy: 0.78 (+/- 0.46)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) minf, maxf, mean, std, dc, power_spec_entropy\n",
      "[ True  True  True  True False False  True False  True]\n",
      "[1 1 1 1 4 3 1 2 1]\n",
      "(27, 6)\n",
      "SVM - Accuracy: 0.75 (+/- 0.44)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) minf, maxf, mean, std, dc, energy, power_spec_entropy\n",
      "[ True  True  True  True False False  True  True  True]\n",
      "[1 1 1 1 3 2 1 1 1]\n",
      "(27, 7)\n",
      "SVM - Accuracy: 0.79 (+/- 0.43)\n",
      "------------------------------------------------------------------\n",
      "Keep feature(s) minf, maxf, mean, std, mean_squared_jerk, dc, energy, power_spec_entropy\n",
      "[ True  True  True  True False  True  True  True  True]\n",
      "[1 1 1 1 2 1 1 1 1]\n",
      "(27, 8)\n",
      "SVM - Accuracy: 0.75 (+/- 0.44)\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "use_1 = True \n",
    "\n",
    "if use_1:\n",
    "    print(\"Use set train_data_1 !\")\n",
    "    dta_train = train_data_1_r\n",
    "    lbl_train = train_labels_1_r\n",
    "    num_of_features = num_of_features_1\n",
    "    features = features1\n",
    "    num_of_windows = num_of_windows1\n",
    "else:\n",
    "    print(\"Use set train_data_2 !\")\n",
    "    dta_train = train_data_2_r\n",
    "    lbl_train = train_labels_2_r\n",
    "    num_of_features = num_of_features_2\n",
    "    features = features2\n",
    "    num_of_windows = num_of_windows2\n",
    "\n",
    "for d in np.arange(1, num_of_features):\n",
    "    clf = svm.SVC(kernel='linear', C=1)\n",
    "    selector = RFE(clf, n_features_to_select=d, step=1)\n",
    "    selector = selector.fit(dta_train, lbl_train)\n",
    "    support = selector.support_\n",
    "    feature_ranks = list(compress(features, support))\n",
    "    print(\"Keep feature(s) %s\" % \", \".join(feature_ranks))\n",
    "    print(support)\n",
    "    ranking = selector.ranking_\n",
    "    print(ranking)\n",
    "    dta_train_subset = dta_train[:, support]\n",
    "    multiplier = int(dta_train_subset.shape[0]/num_of_windows)\n",
    "    b_mask = create_row_mask([True, False, True, False, True], multiplier)\n",
    "    dta_train_subset = dta_train_subset[b_mask, :]\n",
    "    lbl_train_subset = lbl_train[b_mask]\n",
    "    print(dta_train_subset.shape)\n",
    "    \n",
    "    clf = svm.SVC(kernel='rbf', C=1)\n",
    "    scores_svm = cross_validation.cross_val_score(clf, dta_train_subset, lbl_train_subset, cv=12)\n",
    "    print(\"SVM - Accuracy: %0.2f (+/- %0.2f)\" % (scores_svm.mean(), scores_svm.std() * 2))\n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 1)\n",
      "features to keep std\n",
      "SVM - Accuracy: 0.73 (+/- 0.36)\n",
      "------------------------------------------------------------------\n",
      "(45, 2)\n",
      "features to keep minf, std\n",
      "SVM - Accuracy: 0.71 (+/- 0.44)\n",
      "------------------------------------------------------------------\n",
      "(45, 3)\n",
      "features to keep minf, std, energy\n",
      "SVM - Accuracy: 0.75 (+/- 0.33)\n",
      "------------------------------------------------------------------\n",
      "(45, 4)\n",
      "features to keep minf, maxf, std, energy\n",
      "SVM - Accuracy: 0.75 (+/- 0.26)\n",
      "------------------------------------------------------------------\n",
      "(45, 5)\n",
      "features to keep minf, maxf, std, median, energy\n",
      "SVM - Accuracy: 0.72 (+/- 0.31)\n",
      "------------------------------------------------------------------\n",
      "(45, 6)\n",
      "features to keep minf, maxf, std, median, energy, power_spec_entropy\n",
      "SVM - Accuracy: 0.77 (+/- 0.36)\n",
      "------------------------------------------------------------------\n",
      "(45, 7)\n",
      "features to keep minf, maxf, mean, std, median, energy, power_spec_entropy\n",
      "SVM - Accuracy: 0.73 (+/- 0.42)\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for d in np.arange(1, num_of_features):\n",
    "    # ANOVA SVM-C\n",
    "    # 1) anova filter, take X best ranked features, f_classif, mutual_info_classif\n",
    "    anova_filter = SelectKBest(f_classif, k=d)\n",
    "    \n",
    "    dta_train_subset = anova_filter.fit_transform(dta_train, lbl_train)\n",
    "    print(dta_train_subset.shape)\n",
    "    # keep selected feature names\n",
    "    feature_names = [features[i] for i\n",
    "                             in anova_filter.get_support(indices=True)]\n",
    "    print(\"features to keep %s\" % ', '.join(feature_names))\n",
    "    \n",
    "    # 2) svm\n",
    "    clf = svm.SVC(kernel='rbf', C=1)\n",
    "    scores_svm = cross_validation.cross_val_score(clf, dta_train_subset, lbl_train, cv=12)\n",
    "    print(\"SVM - Accuracy: %0.2f (+/- %0.2f)\" % (scores_svm.mean(), scores_svm.std() * 2))\n",
    "    print(\"------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
